{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 自定义块"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0824,  0.0753,  0.1267,  0.2812,  0.1587, -0.0436,  0.0294,  0.1297,\n          0.1116, -0.0391],\n        [-0.0793,  0.0860, -0.0221,  0.2465,  0.0553,  0.0068,  0.1423,  0.1995,\n         -0.0367, -0.0254]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    # 用init方法声明网络的层次结构\n",
    "    def __init__(self):\n",
    "        # 调用父类Module的构造函数来执行必要的初始化\n",
    "        # 这样在类实例化时也可以指定其他函数参数,例如模型参数params\n",
    "        super().__init__()\n",
    "        # 隐藏层\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        # 输出层\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    # 定义模型的正向传播,即如何根据输入X返回所需的模型输出\n",
    "    def forward(self, X):\n",
    "        # 注意:这里我们使用ReLU的函数版本,其在nn.functional模块中定义\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "\n",
    "net = MLP()\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 顺序块"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.1698,  0.0152,  0.0542,  0.2061,  0.2325,  0.0515, -0.0873,  0.1390,\n         -0.2947,  0.0201],\n        [-0.0384, -0.0030,  0.0714,  0.1796,  0.1691,  0.0817, -0.0391,  0.1210,\n         -0.1731, -0.0262]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for block in args:\n",
    "            # block是Module子类的一个实例,把它保存在Module类的成员变量_modules中(OrderedDict类型)\n",
    "            self._modules[block] = block\n",
    "\n",
    "    def forward(self, X):\n",
    "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 作用\n",
    "\n",
    "* 可以在进行许多自定义的操作，例如在正向传播函数中执行代码\n",
    "* 有可能导致效率问题 (Python的全局解释器锁问题)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}